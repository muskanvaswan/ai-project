{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63173c65add4436a83eb931f266c40cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92bd570bd66a4a7285f78473dbdf3f15",
              "IPY_MODEL_bfdb95d84b6646f19e51066e1f8cd9f8",
              "IPY_MODEL_8cd087f974b74347be10690a9a0f94bc"
            ],
            "layout": "IPY_MODEL_b113e1e98e43453ca7f2dc5afa513bd3"
          }
        },
        "92bd570bd66a4a7285f78473dbdf3f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5913c901587544138137900210fa898e",
            "placeholder": "​",
            "style": "IPY_MODEL_e81be94e39c1463a9e929b95fe8bddaf",
            "value": "100%"
          }
        },
        "bfdb95d84b6646f19e51066e1f8cd9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2cf514bb8c44ea6aacef60a27da383f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009004b2689b4a64960ac01c005cfc40",
            "value": 3
          }
        },
        "8cd087f974b74347be10690a9a0f94bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658e139955ff47c89ae83a4a74a758d1",
            "placeholder": "​",
            "style": "IPY_MODEL_0c1838f910aa428291c137c9b5b35ef0",
            "value": " 3/3 [00:03&lt;00:00,  1.22it/s]"
          }
        },
        "b113e1e98e43453ca7f2dc5afa513bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5913c901587544138137900210fa898e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81be94e39c1463a9e929b95fe8bddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2cf514bb8c44ea6aacef60a27da383f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009004b2689b4a64960ac01c005cfc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "658e139955ff47c89ae83a4a74a758d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1838f910aa428291c137c9b5b35ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Text Summarisation and Sentiment Analysis**"
      ],
      "metadata": {
        "id": "Iz7vFAWtlH5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up:\n",
        "This step involves installing the packages and importing them proactively"
      ],
      "metadata": {
        "id": "NcXa8KVxP7hQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xao7K62UnWKF"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install datasets contractions rouge tensorflow transformers"
      ],
      "metadata": {
        "id": "nuGBamfD6U2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12ccf79-1b91-423e-9b3a-b5759e1e4544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.73)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for data\n",
        "import datasets  #(1.13.3)\n",
        "import pandas as pd  #(0.25.1)\n",
        "import numpy as np #(1.16.4)\n",
        "\n",
        "# for plotting\n",
        "import matplotlib.pyplot as plt  #(3.1.2)\n",
        "import seaborn as sns  #(0.9.0)\n",
        "\n",
        "# for preprocessing\n",
        "import re\n",
        "import nltk  #(3.4.5)\n",
        "import contractions  #(0.0.18)\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "\n",
        "# for evaluation\n",
        "import rouge  #(1.0.0)\n",
        "import difflib\n",
        "\n",
        "# for extracted frequency based approach\n",
        "from heapq import nlargest\n",
        "\n",
        "# for textrank\n",
        "import gensim  \n",
        "\n",
        "# for seq2seq\n",
        "from tensorflow.keras import callbacks, models, layers, preprocessing as kprocessing #(2.6.0)\n",
        "\n",
        "# for bart\n",
        "import transformers  #(3.0.1)\n",
        "\n",
        "# for code cleanliness\n",
        "from IPython.core.display import display, HTML\n"
      ],
      "metadata": {
        "id": "iihvl21ds2fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "CANia4H-6UPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27b3ec0-4344-43a1-f094-9447756177e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data\n",
        "\n",
        "Here we are loading a sample dataset of news articles and their highlights which will be considered the aim of our text summarisation alogrithms.\n",
        "\n",
        "This Dataset is availabe in the datasets package imported above."
      ],
      "metadata": {
        "id": "89sCzxmYQGqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"cnn_dailymail\", '3.0.0')"
      ],
      "metadata": {
        "id": "nflkDcbV65Mh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "63173c65add4436a83eb931f266c40cf",
            "92bd570bd66a4a7285f78473dbdf3f15",
            "bfdb95d84b6646f19e51066e1f8cd9f8",
            "8cd087f974b74347be10690a9a0f94bc",
            "b113e1e98e43453ca7f2dc5afa513bd3",
            "5913c901587544138137900210fa898e",
            "e81be94e39c1463a9e929b95fe8bddaf",
            "b2cf514bb8c44ea6aacef60a27da383f",
            "009004b2689b4a64960ac01c005cfc40",
            "658e139955ff47c89ae83a4a74a758d1",
            "0c1838f910aa428291c137c9b5b35ef0"
          ]
        },
        "outputId": "9fceaabb-2ec0-4665-c8c9-ef76a80305dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63173c65add4436a83eb931f266c40cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(dataset['train'])).rename(columns={\"article\":\"text\", \n",
        "      \"highlights\":\"y\"})[[\"text\",\"y\"]].head(10000)\n",
        "\n",
        "SAMPLES = 20\n",
        "df_train = df.iloc[SAMPLES + 1: 4 * SAMPLES]\n",
        "df_test = df.iloc[:SAMPLES + 1]"
      ],
      "metadata": {
        "id": "Xl4ORTj8NUL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Evaluation Functions\n",
        "\n",
        "To compare the models that we will be using in this proeject, it is important to define parameters of comparison. Here we are going to use the 'rougue' library to evaluate our summaries\n"
      ],
      "metadata": {
        "id": "tSPYMa_4RUOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summary(expected: list, predicted: list):    \n",
        "  rouge_score = rouge.Rouge()    \n",
        "  scores = rouge_score.get_scores(expected, predicted, avg=True)       \n",
        "  score_1 = round(scores['rouge-1']['f'], 2)    \n",
        "  score_2 = round(scores['rouge-2']['f'], 2)    \n",
        "  score_L = round(scores['rouge-l']['f'], 2)    \n",
        "  print(\"rouge1:\", score_1, \"| rouge2:\", score_2, \"| rougeL:\",\n",
        "        score_2, \"--> avg rouge:\", round(np.mean(\n",
        "        [score_1,score_2,score_L]), 2))"
      ],
      "metadata": {
        "id": "rqet1sJhRtZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Visualisation Functions\n",
        "\n",
        "It is useful for our purposes to be able to see what parts of the full text and the summary match one another. This will allow us to see what parts were extracted and considered important\n",
        "\n",
        "This part of the code has been adapted from:\n",
        "https://gist.github.com/mdipietro09/8c9d50476488b12b34694e1292a67f80#file-display_string_matching-py"
      ],
      "metadata": {
        "id": "fxJEJCTsUcWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sentences(a: str, b: str):\n",
        "  match = difflib.SequenceMatcher(isjunk=None, a=a, b=b, autojunk=True)\n",
        "  lst_match = [block for block in match.get_matching_blocks() if block.size > 20]\n",
        "  if len(lst_match) == 0:\n",
        "      lst_a, lst_b = nltk.sent_tokenize(a), nltk.sent_tokenize(b)\n",
        "  else:\n",
        "      first_m, last_m = lst_match[0], lst_match[-1]\n",
        "      string = a[0 : first_m.a]\n",
        "      lst_a = [t for t in nltk.sent_tokenize(string)]\n",
        "      for n in range(len(lst_match)):\n",
        "          m = lst_match[n]\n",
        "          string = a[m.a : m.a+m.size]\n",
        "          lst_a.append(string)\n",
        "          if n+1 < len(lst_match):\n",
        "              next_m = lst_match[n + 1]\n",
        "              string = a[m.a+m.size : next_m.a]\n",
        "              lst_a = lst_a + [t for t in nltk.sent_tokenize(string)]\n",
        "          else: break\n",
        "      string = a[last_m.a+last_m.size :]\n",
        "      lst_a += [t for t in nltk.sent_tokenize(string)]\n",
        "      string = b[0 : first_m.b]\n",
        "      lst_b = [t for t in nltk.sent_tokenize(string)]\n",
        "      for n in range(len(lst_match)):\n",
        "          m = lst_match[n]\n",
        "          string = b[m.b : m.b+m.size]\n",
        "          lst_b.append(string)\n",
        "          if n+1 < len(lst_match):\n",
        "              next_m = lst_match[n+1]\n",
        "              string = b[m.b+m.size : next_m.b]\n",
        "              lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
        "          else:\n",
        "              break\n",
        "      string = b[last_m.b+last_m.size :]\n",
        "      lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
        "  return lst_a, lst_b\n",
        "\n",
        "def display_string_matching(a: str, b: str, both=True, sentences=True, titles=[]) -> str:\n",
        "  if sentences:\n",
        "      lst_a, lst_b = split_sentences(a, b)\n",
        "  else:\n",
        "      lst_a, lst_b = a.split(), b.split()       \n",
        "  first_text = []\n",
        "  for i in lst_a:\n",
        "      if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_b]:\n",
        "          first_text.append('<span style=\"background-color:rgba(255,215,0,0.3);\">' + i + '</span>')\n",
        "      else:\n",
        "          first_text.append(i)\n",
        "  first_text = ' '.join(first_text)\n",
        "  second_text = []\n",
        "  if both is True:\n",
        "      for i in lst_b:\n",
        "          if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_a]:\n",
        "              second_text.append('<span style=\"background-color:rgba(255,215,0,0.3);\">' + i + '</span>')\n",
        "          else:\n",
        "              second_text.append(i)\n",
        "  else:\n",
        "      second_text.append(b) \n",
        "  second_text = ' '.join(second_text)\n",
        "\n",
        "  if len(titles) > 0:\n",
        "      first_text = \"<strong>\"+titles[0]+\"</strong><br>\"+first_text\n",
        "  if len(titles) > 1:\n",
        "      second_text = \"<strong>\"+titles[1]+\"</strong><br>\"+second_text\n",
        "  else:\n",
        "      second_text = \"---\"*65+\"<br><br>\"+second_text\n",
        "  final_text = first_text +'<br><br>'+ second_text\n",
        "  return final_text"
      ],
      "metadata": {
        "id": "3TpP3Bj2U8gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualise_differance(full_text: str, summary: str):\n",
        "  html = display_string_matching(full_text, summary)\n",
        "  display(HTML(html))\n"
      ],
      "metadata": {
        "id": "Et5K55hCWivZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing an Extractive Appoach based on Frequency Method\n",
        "\n",
        "This is the first straightforward approach where we measure the frequency of sentences and then score sentences and pick the n largest ones to construct the summary\n",
        "\n",
        "This approach is created manually using no external packages."
      ],
      "metadata": {
        "id": "sEs9l6WZXR4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessed(document):\n",
        "  from string import punctuation\n",
        "  punctuation = punctuation + '\\n'\n",
        "  stopwords = list(STOP_WORDS)\n",
        "  return [word for word in document if word.text.lower() not in stopwords and word.text.lower() not in punctuation]\n",
        "\n",
        "def get_normalised_word_frequencies(document):\n",
        "  word_frequencies = {}\n",
        "  for word in preprocessed(document):\n",
        "      word_frequencies[word.text] = 1 if word.text not in word_frequencies else word_frequencies[word.text] + 1\n",
        "  max_frequency = max(word_frequencies.values())\n",
        "  for word in word_frequencies:\n",
        "    word_frequencies[word] /= max_frequency\n",
        "  return word_frequencies\n",
        "\n",
        "def extracted_summary(text: str, percentage_reduced = 0.1) -> str:\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  doc = nlp(text)\n",
        "  tokens = [token.text for token in doc]\n",
        "  word_frequencies = get_normalised_word_frequencies(doc)\n",
        "  sentence_scores = {sent: sum([word_frequencies[word.text.lower()] \n",
        "                                for word in sent if word.text.lower() in word_frequencies]) \n",
        "                                for sent in list(doc.sents)}\n",
        "  select_length = int(len(list(doc.sents)) * percentage_reduced)\n",
        "  summary = nlargest(select_length, sentence_scores, key = sentence_scores.get) \n",
        "  return ' '.join([word.text for word in summary])\n"
      ],
      "metadata": {
        "id": "UAVOdM0RsBXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extracted_approach(corpus, percentage_reduced=0.2):    \n",
        "    if type(corpus) is str:        \n",
        "       corpus = [corpus]    \n",
        "    return [extracted_summary(txt, percentage_reduced=percentage_reduced) for txt in corpus]    "
      ],
      "metadata": {
        "id": "ZRTKgPIwMEZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_summaries = extracted_approach(df_test[\"text\"], percentage_reduced=0.2)"
      ],
      "metadata": {
        "id": "6tyEJ-x0aqCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_predicted_summary, sample_expected_summary = predicted_summaries[0], df_test[\"y\"][0]\n",
        "evaluate_summary(sample_predicted_summary, sample_expected_summary)\n",
        "print(f\"For {SAMPLES} summaaries:\")\n",
        "evaluate_summary(predicted_summaries, list(df_test[\"y\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8serPAmNMxSj",
        "outputId": "393d69e0-392e-4cd6-d574-ea232c5c42ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1: 0.25 | rouge2: 0.17 | rougeL: 0.17 --> avg rouge: 0.22\n",
            "For 20 summaaries:\n",
            "rouge1: 0.22 | rouge2: 0.07 | rougeL: 0.07 --> avg rouge: 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_differance(sample_predicted_summary, df_test[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "-fWGQ4hvb76k",
        "outputId": "bb2d8843-3fd5-422b-e297-d3c6ccc4a0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:rgba(255,215,0,0.3);\">At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart.</span> <span style=\"background-color:rgba(255,215,0,0.3);\"> Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. </span> <span style=\"background-color:rgba(255,215,0,0.3);\">\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. </span> <span style=\"background-color:rgba(255,215,0,0.3);\">Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters.</span><br><br>---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br><br>LONDON, England (Reuters) -- <span style=\"background-color:rgba(255,215,0,0.3);\"> Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. </span> <span style=\"background-color:rgba(255,215,0,0.3);\">Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. </span> \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" <span style=\"background-color:rgba(255,215,0,0.3);\">At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart.</span> Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" <span style=\"background-color:rgba(255,215,0,0.3);\">Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters.</span> E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another Extractive Approach:  The TextRank Algorithm \n",
        "\n",
        "Based on the the page rank algorithm (by google) from the original internet days, this approach is also extractive and similar to the frequency mehtod. For this we are using a pretrained model form genism"
      ],
      "metadata": {
        "id": "5qqMyHyD1O_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textrank(corpus, ratio=0.2):    \n",
        "    if type(corpus) is str:        \n",
        "       corpus = [corpus]    \n",
        "    return [gensim.summarization.summarize(txt, ratio=ratio) for txt in corpus]    "
      ],
      "metadata": {
        "id": "3AoHjIczzp8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_summaries = textrank(corpus=df_test[\"text\"], ratio=0.2)"
      ],
      "metadata": {
        "id": "0j5DPKO615Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_predicted_summary, sample_expected_summary = predicted_summaries[0], df_test[\"y\"][0]\n",
        "evaluate_summary(sample_predicted_summary, sample_expected_summary)\n",
        "print(f\"For {SAMPLES} summaaries:\")\n",
        "# len(predicted_summaries), len(list(df_test[\"y\"]))\n",
        "evaluate_summary(predicted_summaries, list(df_test[\"y\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fqKBxZA1-DP",
        "outputId": "9a3093b4-31ce-499d-bf97-2439752718a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1: 0.27 | rouge2: 0.18 | rougeL: 0.18 --> avg rouge: 0.24\n",
            "For 20 summaaries:\n",
            "rouge1: 0.25 | rouge2: 0.09 | rougeL: 0.09 --> avg rouge: 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_differance(sample_predicted_summary, df_test[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MXt9QXZj2WSB",
        "outputId": "52042598-ef01-4a85-d6dc-4f0d50fd4564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:rgba(255,215,0,0.3);\">LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">\"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.</span><br><br>---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br><br><span style=\"background-color:rgba(255,215,0,0.3);\">LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.</span> <span style=\"background-color:rgba(255,215,0,0.3);\">\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month.</span>  \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. <span style=\"background-color:rgba(255,215,0,0.3);\">\"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.</span>   Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An Abstractive Approach:  Seq2Seq\n",
        "\n",
        "This approach uses the famous sequence to sequence nueral network."
      ],
      "metadata": {
        "id": "85-JXz3B22Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessed(text: str) -> str:\n",
        "    text = re.sub(r'\\.(?=[^ \\W\\d])', '. ', str(text))\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = \" \".join([word.strip() for word in text.split()])\n",
        "    text = contractions.fix(text.lower())   \n",
        "    tokens = text.split()\n",
        "    stemmer = nltk.stem.porter.PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    tokens = [lem.lemmatize(word) for word in tokens]\n",
        "    stopwords = [\"cnn\",\"say\",\"said\",\"new\"] + list(STOP_WORDS)\n",
        "    tokens = [word for word in tokens if word not in stopwords]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "-HZT9DUc2tRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"text_clean\"] = df_train[\"text\"].apply(preprocessed)\n",
        "df_train[\"y_clean\"] = df_train[\"y\"].apply(preprocessed)\n",
        "df_test[\"text_clean\"] = df_test[\"text\"].apply(preprocessed)\n",
        "df_test[\"y_clean\"] = df_test[\"y\"].apply(preprocessed)"
      ],
      "metadata": {
        "id": "naOtE5a15PvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7118797-72b8-4186-9b8a-db28de89b8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency(column):\n",
        "  tokens = nltk.tokenize.word_tokenize(column.str.cat(sep=\" \"))\n",
        "  ngrams = [1]\n",
        "  df_freq = pd.DataFrame()\n",
        "  for n in ngrams:\n",
        "    dic_words_freq = nltk.FreqDist(nltk.ngrams(tokens, n))\n",
        "    df_n = pd.DataFrame(dic_words_freq.most_common(), columns=\n",
        "                          [\"word\",\"freq\"])\n",
        "    df_n[\"ngrams\"] = n\n",
        "    df_freq = df_freq.append(df_n)\n",
        "    df_freq[\"word\"] = df_freq[\"word\"].apply(lambda x: \" \".join(string for string in x))\n",
        "    df_freq_X = df_freq.sort_values([\"ngrams\",\"freq\"], ascending=\n",
        "                          [True,False])\n",
        "  return df_freq, df_freq_X"
      ],
      "metadata": {
        "id": "cKrj_9B95lsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq_x = frequency(df_train[\"text_clean\"])[1]\n",
        "df_freq_y = frequency(df_train[\"y_clean\"])[1]"
      ],
      "metadata": {
        "id": "XdZ81DfU_eiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x=\"freq\", y=\"word\", hue=\"ngrams\", dodge=False,\n",
        " data=frequency(df_train[\"text_clean\"])[0].groupby('ngrams')[\"ngrams\",\"freq\",\"word\"].head(30))\n",
        "plt.show()\n",
        "\n",
        "sns.barplot(x=\"freq\", y=\"word\", hue=\"ngrams\", dodge=False,\n",
        " data=frequency(df_train[\"y_clean\"])[0].groupby('ngrams')[\"ngrams\",\"freq\",\"word\"].head(30))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "qJiyLukP-I57",
        "outputId": "79763914-d545-4776-bb18-b11c36d754c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEHCAYAAAB1IpuHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7zVVZ3/8ddbQFEh8dpoVKhpIBePcrwQyuT1p2aWqcMkXdBGx9KsTCcrm7SxstFmsvJaEppkjndHKzVFQPLCRRAQ8JI4UWSKiqBiAp/fH2tt3B73OWcD+3rO+/l4nMf57u9e3+9eXzfyYX2/n/VZigjMzMxqYaN6d8DMzLoPBx0zM6sZBx0zM6sZBx0zM6sZBx0zM6sZBx0zM6uZnvXuQKPbZpttYsCAAfXuhplZ05gxY8YLEbFtqfccdDrxes++xAGn17sbZmY1M+PCz2zQ8ZKebe+9LnV7TdJZkk7P2/8t6b68faCkCZIukzRd0jxJ59W3t2Zm3U+XCjrAFGD/vN0K9JHUK++bDHwzIlqBYcA/ShpWn26amXVPXS3ozACGS3oX8AbwICn47E8KSP8kaSbwKDAY2K3USSSdnEdE01e9trw2PTcz6wa6VNCJiDeBZ4CxwB9IgeYA4APA68CZwEERMQy4E+jdznmujIjWiGjtuVnfWnTdzKxb6FJBJ5tCCi6T8/YppJHNu4BXgWWS3g0cXrcempl1U10xe20K8E3gwYh4VdIqYN+ImC3pUWAB8CfgRdq5vVZsUP+tmb6BmRxmZpaoqy9tIGkAcEdEDFmf4zf/hx1j4Ked6GZdz4amxZq1R9KMnLT1Dl3x9lopPST9LKdK3y1pU0njJR1b746ZmXUn3SXo7AJcEhGDgZeBY+rcHzOzbqm7BJ1nImJW3p4BDOiosVOmzcyqo7sEnTeKtlfTSQKFU6bNzKqjuwQdMzNrAF0xZbqinDJtZlY5XW6kI6mfpC/k7Q8DPy1Ol46IiyLiXGAV8HhdOmlm1k11xZFOP+ALwKUdNYqIfynnZPMXL2X4WddUol9mgOfHWPfW5UY6wAXAzpJmAReSKk3fKGlBXt5AAJLul1Ry8pKZmVVHVxzpnA0MiYiWfHvtNlJF6b8AU4GRwAMdnUDSycDJABv33bqqnTUz60664kinrUciYnFErAFm0ckcHXDKtJlZtXSHoLNOc3TMzKx6uuJfwMuBig1PnDJtZlY5XS7oRMRSSbMkrQTmAM/Vu09mZpZ0yaUNNnQ5g2Je2sDAac5m66K7Lm1QajmDkyRNkzRb0k2SNqt3J83MupOuHHRKLWdwc0TsFRG7A/OBz9Wzg2Zm3U2Xe6ZTpNRyBkMknU+qWtAHuKvUgZ6nY2ZWHV15pFMqVXo8cFpEDAXOA3qXOtDzdMzMqqMrB51S+gJLJPUCxtS7M2Zm3U3T3l6TNJ6UoXZjm/07kIt95jI4ZwL357e/BTwMPA8MBO7s7HM8T8fMrHKaNui0JyL+AhwBa4MOEXFRUZPL8nuLgC92dj5Xma4vpyqbdS1Nc3tN0mckPZbTnX+Zd4+S9AdJf5R0bG43QNLcEsdvnVOn50n6OaBa9t/MzJok6EgaDJwDHJjTnb+U39oe2A84krSkQUe+DTyQU6hvAd5Xpe6amVk7muX22oHADRHxAkBEvJiXxbk1V49+XNK7OznHKOAT+fg7Jb3UXkOnTJuZVUdTjHQ6UJwWXbHbZU6ZNjOrjmYJOvcBx0naGkDSVutxjsnA8fn4w4EtK9c9MzMrR1PcXouIeZK+C0yStBp4dD1Ocx5wnaR5wB+A/yvnIKdMm5lVTpesMr0uJPWIiNXtve8q05Xj9Gez7qHLVJmW9B1JXy56/V1JX5J0Vq4e/Zik84rev1XSjJwmfXLR/hWSfihpNjCixpdhZtZtNVXQAcYBnwGQtBHwz8BfSRWl9wZagOGSRuX2J0bEcKAVOL3wTAjYHHg4InaPiAdqeQFmZt1ZUzzTKYiIRZKWStoDeDfp2c5ewKG89ZynDykITSYFmqPz/vfm/UtJBUBvau9znDJtZlYdTRV0sp8DY4F/II18DgK+HxFXFDfKJXAOBkZExGuS7uetqtIrO3qOExFXAldCeqZT4f6bmXVbzXZ7DVI1gcNII5y78s+JkvoASHqPpO2ALYCXcsAZCOxbrw6bmVnSdCOdiPi7pInAy3m0crekQcCDuUrBCuBTwO+AUyTNBxYCD63P5zll2syschou6Eg6Hfg8MDMixhTtbyUlEXyZNGo5rvBeRFwMXFzidIe38zGnSfppRJxWsY6bmVmnGi7oAF8ADo6IxYUdknpGxHRJrwFPAbdExJO16IyXNiiP5+CYWTkaKuhIuhzYCfitpPcBt+fX/yfpCuDMiNhJ0uaSxgFDgF7AuRFxm6SxwFHAZsDOpOD0b/ncJwBfB14GZvP2um1mZlYDDZVIEBGnAH8BDgD+G9iNNOr5ZJum3wTui4i9c9sLJW2e32sBRgNDgdGS3itpe1IZnJGkpRB266gfkk6WNF3S9FWvLa/Q1ZmZWUONdEq4PSJeL7H/UOAoSWfm1715a32ceyNiGYCkx4H3A9sA90fE83n/9cCu7X2oU6bNzKqj0YPOq+3sF3BMRCx8205pH95+22w1jX+NZmbdRrP+hXwX8EVJX4yIkLRHRHRUefph4OJcBucVUubb7HI+yCnTZmaV01DPdNbBf5ASCB7LSx38h6QdgFMBJI2V9NNC44hYApwLPAhMBebXvMdmZtb8SxtIWhERfdrsGwu0VmIejpc2KM0p0mbWni6ztEFHJA2QNLfE/o9IelDSNpIOzdszJd1QKJ1jZma10WWCTim5wvTZwBF51zmkFOw9genAGfXqm5lZd9SsiQTlOJC0js6hEfGKpCNJ83Om5hptG5Oe8byDlzYwM6uOrhx0niZVM9iVNKoRcE+Jiabv4Hk6ZmbV0ZVvrz0LHANcI2kwqcr0SEkfAMildNqdIGpmZpXXlUc6RMQCSWOAG4CPkhZ/u07SJsCWpLk6R3Z0Ds/TMTOrnKZPmV5f5aZVO2X6nZwubWYdacqU6ZwCvUDSBEnzJd0oaTNJwyVNkjRD0l25mCeSWiQ9JOkxSbdI2jLvv1/SxZJmSZorae/6XpmZWffVsEEn+yBwaUQMIpWvORX4CXBsRAwHxgHfzW2vAb4WEcOAOcC3i86zWUS0kNbqGVerzpuZ2ds1+jOdP0XE1Lx9LfAN0ho69+S05x7AEklbAP0iYlJuezXpOU7BdQARMVnSuyT16+hDnTJtZlYdjR502j5wWg7Mi4gRxTtz0FmX83T4IMsp02Zm1dHot9feJ6kQYI4npT1vW9gnqZekwXn9nJck7Z/bfhqYVHSe0bn9fsCywno7ZmZWW40+0lkInJqXpn6c9DznLuDHeXTTE/gRMA/4LHC5pM2APwInFJ1npaQ5pIXeDpH0YeDLwAOddcAp02ZmldPoQWdVRHyqzb5ZwKi2DSNiFrBvO+e5NiK+XHiRg87icqpQz1+8lOFnXVN+j7sIp0WbWTU08u21jwM75VTnKyT1kLRC0oWS5kn6vaS9c0r0HyUdBWtTrafkStIzgXcV7X9HFWozM6udhgw6kgYBBwFb5FTn1cAYYHPgvogYTEoqOB84BDga+E4+/G/AIbmS9GhgTURMr/ElmJlZCY16e+0gYDgwLadGb0oKJn8HfpfbzAHeiIg38/OaAXl/L+CnkgrBap3rqzll2sysOho16Ai4OiK+/rad0pnxVt2eNcAbABGxRlLhWr4CPAfsThrJrVzXD3fKtJlZdTTk7TXgXuBYSdsBSNpK0vvLPHYLYElErCGlTveoUh/NzGwdNeRIJyIel3QOcLekjYA3SSVwynEpcJOkz5Buxb26IX1xyrSZWeU0TZXpXLrm+Ii4VNIOwI8j4thqf25ra2tMn+48BDOzcnVUZbqZgs4A4I6IGFLLz+2OSxt4jo6ZbYiOgk5D3l5rxwXAzpJmAU8CgyJiSF4X5+OkdOpdgIuAjUnPc94AjoiIFyXtDFwCbAu8BpwUEQtqfxlmZt1XoyYSlHI28HSet3NWm/eGAJ8A9iItdfBaROwBPAgU/tl+JfDFvCTCmaRnPyVJOlnSdEnTV722vMKXYWbWfTXTSKcjEyNiObBc0jLgf/P+OcAwSX2ADwE35Hk/AJu0dzKnTJuZVUdXCTpvFG2vKXq9hnSNGwEv51GSmZnVSTMFneVA3/U5MCJekfSMpOMi4gal4c6wiJjd2bFOmTYzq5ymeaYTEUuBqblo54XrcYoxwOckzSYthfCxSvbPzMw61zQp0/XSnVKmnSptZpXQUcp004x0KkXS5pLulDRb0lxJo+vdJzOz7qKZnulUymHAXyLiIwB5BVIzM6uBbjfSIaVRHyLpB5L2j4hlbRt4no6ZWXV0u6ATEU8Ae5KCz/mS/r1EmysjojUiWntutl4Jc2ZmVkK3u72Wi4W+GBHXSnoZ+Jd698nMrLvodkEHGAr8PFcueB34fEeNPU/HzKxyGjbo5AmcyouxVdLvgaeBMyOi0zUL5i9eyvCzrqlwFxqP06XNrBYa6pmOpAGSFkq6BpgLfEvSNEmPSTqvqM0CSRMkzZd0o6TN8nsHSXpU0hxJ4yRtkvcvyokDM4FPAq3ABEmzJG1ap8s1M+t2GiroZLuQKkB/BXgPsDfQAgyXNCq3+SBwaUQMAl4BviCpNzAeGB0RQ0mjuOJbZ0sjYs+IuBaYDoyJiJaIeL0WF2VmZo0ZdJ6NiIeAQ/PPo8BMYCApIAH8KSKm5u1rgf1IgeiZnJ0GcDUwirdcX24HnDJtZlYdjfhM59X8W8D3I+KK4jfzCqJta/eUU8vn1c6b5JN5aQMzs6poxJFOwV3AiXktHCS9R9J2+b33SRqRt48HHgAWAgMkfSDv/zQwqZ1zr3fFajMzW3+NONIBICLuljQIeDAvvLYC+BSwGvgbcLqkccDjwGURsVLSCaSF2noC04CehSSDNsYDl0t6HRjR0XMdp0ybmVVO01WZzrfXngB2iIgXOmm7CGjtrF1HukOVaadLm1klNXWV6bZVoYEvkUZoEyVNzG0uyw/+5xWlVp8O7NCm3aGSHpQ0U9INhVt3ZmZWGw0fdHirKvTuETEEOBf4P+CAiDggt/lmjqrDgH+UNCwifgz8pdBO0jbAOcDBEbEnKW36jFpfjJlZd9YMQafTqtDAP+WJn48Cg4HdSrTZN++fKmkW8Fng/aU+0CnTZmbV0bCJBAUR8YSkPYEjSFWh7y1+X9KOwJnAXhHxkqTxQO8SpxJwT0R8sozPdMq0mVkVdBh0JP2EDubARMTpFe/RO/tQqip0IeX5BeBdpDk4yyS9GzgcuD8fXtzuIeASSR+IiKckbQ68p2gyqZmZVVlnI51CQcyRpFtThVn9x5FSlWthKHChpDXAm6TSNiOA30n6S35e8yiwAPgTMLXo2CvbtBsLXFeoyUZ6xtNh0HHKtJlZ5ZSVMi3pIWC/iFiVX/cCpkTEvlXuX9t+/CEiPlShc50CvBYRHZaQbm1tjenTOy1GbWZmWUcp0+U+09mSdBvrxfy6T95XU6UCjqSehWC4jue6vJx2XXlpA8/PMbNaKzfoXAA8mue7iFRI89xqdao9klZERB9JHwb+A3iJVAh0V0m3Au8lJRFcnJMByFUKvg68DMwG3oiI0ySdC6yIiItqfR1mZt1Vp0FH0kakumb75B+Ar0XEX6vZsTLsCQyJiGfy6xMj4sW8Ps40STcBGwPnAcOBZcBEUlp1hySdDJwMsHHfravRdzOzbqnToBMRayRdEhF7ALfVoE/leqQo4ECqxXZ03n4vaRmEfwDuj4jnASRdD+za2YmdMm1mVh3lTg69V9IxeQnpRrF2qYJ8u+1gUvHO3UmjmVJzdczMrI7Kfabzr6SSMaslrcz7IiLeVZ1urbMtgJci4jVJA0nVBwAeBi6WtDVphdHjSM91yuaUaTOzyikr6EREXdeeyZWl7+igye+AUyTNJz1/egggIpbkhIEHSYkEs6raUTMz61DZSxtIOoq3ln++PyI6CgIVVQg6ueDnhpxnLGmpg9PKPaYrLW3gFGkzq4UNXtpA0gWkJQUezz9fkvT9ynWxLD0k/SwvX3C3pE0ltUh6SNJjkm6RtGXu7/2SWvP2NnldHUhLHRwnaVY+ZpcaX4OZWbdWbiLBEcAhETEuIsaRlhv4SPW6VdIuwCURMZh0q+wY4BpS+vYwUjXqb3dyju2BMyKiBWgFFlexv2Zm1sa6LG3Qr2h7i0p3pAzPREThmcwMYGegX0RMyvuu5q3bf+15EPiGpK8B729vmWovbWBmVh3lBp3vATMljZd0Nekv/e9Wr1slvVG0vZq3B8G2VvHWta1NnY6IXwFHAa8Dv5F0YKmDI+LKiGiNiNaem9U1h8LMrEspN+gcCYwjBZsbSfNhru/4kKpbBrwkaf/8+tNAYdSziFSFAODYwgGSdgL+mFcVvY200qiZmdVIufN0rgL2J40SdibVYZscERev7wdXKCPts8DlkjYD/gickPdfBPxPLmdzZ1H7fwI+LelN4K+kEVyHPE/HzKxy1iVlugewF3AAcArwekQMXO8PrlAadLU5ZdrMbN1UImX6XtLiaKNJky/32pCAU6SnpAmS5ku6UdJmkoZLmiRphqS7JG2f+/ABSb+XNFvSTEk7S+oj6d78eo6kj+W2AyTNLer/mXmSKJJOl/R4Tpn+dQWuwczMylTu7bXHSM9IhpCepbws6cH2sr/WwQeBz0XEVEnjgFOBo4GPRcTzkkaTEhZOBCYAF0TELZJ6kwLm34GjI+IVSdsAD0m6vZPPPBvYMSLekNRRMoKZmVVYuWVwvgIgqS8wFvgFqYLzJh0cVo4/RURheelrgW+QAts9ubZoD2BJ/tz3RMQtuT8rc396Ad+TNApYA7wHeHcnn/kYMCGvv3NrqQZe2sDMrDrKCjqSTiMlEgwnZYaNA6ZU4PPbPlBaDsyLiBFtPr+9vOUxwLbA8Ih4M1ce6M3bU6bh7RWnP0Kaz/NR4JuShrZdedRLG5iZVUe5KdO9gf8CBkbEwRFxXkTcV4HPf5+kQoA5nlSoc9vCPkm9JA2OiOXAYkkfz/s3yRlrWwB/ywHnAOD9+VzPAdtJ2lrSJqSU78KCdO+NiInA1/LxfSpwHWZmVoZyb69Va0nnhcCp+XnO48BPgLuAKyQNI6VB/wiYR5qHc4Wk7wBvkpYpmAD8r6Q5wHRgQe7vm7ndI8CfC/tJt+uulbQFadntH0fEyx110CnTZmaVU3bKdC01Ujp1V0iZdqq0mdXSBqdM18m6VpX+71wvbb6kvSTdLOlJSecXTijpU5IeyVWmr8hzj8zMrEYaOeisa1Xpv+fIejmpxM2ppEy4sfnZziDSPKORucr0alIigpmZ1Ui583TqoZyq0jcUtS/Mz5lDyoBbAiDpj8B7gf1I2XfTcjr2psDfSn2wU6bNzKqjkYPOulSVLm6/ps2xa0jXKeDqiPh6Zx/slGkzs+po5NtrbXVUVboc9wLHStoOQNJWkt7fyTFmZlZBjTzSKaW9qtKdiojHJZ0D3J3n67xJeu7zbEfHOWXazKxyGjLoRMQiUhJA4XXxPKF9AXLdtOOBSyPiw0Vt7wfuz20GANtExPT83vXA9fm9+0mVC8zMrEYaMuiUqR/wBeDSan7I/MVLGX7WNdX8iKrx/BwzazTNHHQuAHaWNAu4J+87nFTP7fy2K5tK2pRUqHR3UoWCTWvYVzMzo7mDztnAkIhokXQMaWG53YFtSGnRk9u0/zzwWkQMyiV2ZrZ3YqdMm5lVRzNlr3VkP+C6iFgdEc+Rstr2atNmFGn5BCLiMdISByVFxJUR0RoRrT03a6/AtZmZrauuEnTMzKwJNPPtteVAYRgyBfhXSVcDW5FGNWfx9nV0JpOy3e6TNAQYVs6HOGXazKxymnakExFLgamS5gIjSLfLZgP3Af8WEX9tc8hlQB9J84HvkObnnFXDLpuZdXsNubRBNUjqERGri16PBVoj4rSOjmvWpQ2cLm1m9dLwSxtIulXSjLyMwcl532GSZkqaLenevK+PpF9ImpOXNzgm7/9k3jdX0g+KzrtC0g8lzQZGSDpB0hOSHgFG1uNazcy6s0Z5pnNiRLyY59JMk3Qb8DNgVEQ8I2mr3O5bwLKIGAogaUtJOwA/IFWQfolU5ubjEXErsDnwcER8VdL2wK9yu2XARODRWl6kmVl31xAjHeD0PBp5iLQMwcnA5Ih4BiAiXsztDgYuKRwUES+RUqPvj4jnI2IVaQnrUbnJauCmvL1PUbu/k8vhlCLp5Lwg3PRVry2v2EWamXV3dQ86kj5MCiYjImJ30uhjVocHlW9l8XOccnmejplZddQ96ABbAC9FxGuSBpIKevYGRknaEdIyBLntPaTK0OT9WwKPAP8oaZu8/PQnKb3kwcO53daSegHHVe2KzMyspEZ4pvM74JScyryQdIvtedIttjsk7QQ8ABwCnA9cktOkVwPnRcTNks4mPaPZhBTEzs1t1oqIJZLOBR4kLX9d1mjK83TMzCqnoVOm89IEd0TEkE6aFtqfDfSMiPPLbC/Sf4M17bVxyrSZ2bpp+JTpTvSUNEHSfEk3StpM0nBJk3Ka9V2Stpd0BPBl4POSJgJIOiOnUc+V9OW8b4CkhZKuAeaSEhfMzKwGGuH2Wmc+CHwuIqZKGkd6pnM08LGIeF7SaOC7EXGipMuBFRFxkaThpJVF9wEEPCxpEimtehfgsxHxUF2uyMysm2qGoPOniJiat68FvkFaVfSedHeMHsCSEsftB9wSEa8CSLoZ2B+4HXi2o4DjpQ3MzKqjGYJO24dOy4F5ETFiA875aocfGHElcCWkZzob8DlmZlakGZ7pvE9SIcAcT8pu27awT1IvSYNLHDcF+Hh+BrQ56ZbclJr02MzMSmqGkc5C4NT8POdx4CfAXcCPJW1BuobHJLUAA0hVpi+KiJmSxpPm8QD8PCIezRlxZXPKtJlZ5TR0ynS5JC0ADo6Ixe283zOXyFlnTpk2M1s3HaVMN8NIp0M5Y20n4Ld5NLRzRJyWRzkrgT1I6+5cQqrbti3wGnBSRCyoU7fNzLqlpg86EXGKpMOAA4Aj27zdH/hQRKzOyyOcEhFPStoHuBQ4sMbdNTPr1po+6HTihhxw+gAfAm7IadaQSuaU5JRpM7Pq6OpBp5AavRHwckS0lHOQU6bNzKqjGVKmN1hEvAI8I+k4SDXXJO1e526ZmXU7XX2kU2wMcJmkc4BewK+B2Z0d5JRpM7PK6RIp09XU2toa06dPr3c3zMyaRpdOmS7HhszTmb94KcPPuqbSXaoqz9Exs0ZV12c6kr6Vlxl4QNJ1ks6U1CLpIUmPSbpF0paSBkp6pOi4AZLm5O13LHOQ998v6UeSpgNfyq9/IOkRSU9I2r9Ol21m1m3VLehI2gs4BtgdOBwoDMWuAb4WEcOAOcC38yTOjQvLVwOjgevzstM/AY6NiOHAOOC7RR+zcUS0RsQP8+ueEbE3ad2db3fQt5MlTZc0fdVryytyvWZmVt+RzkjgtohYGRHLgf8FNgf6RcSk3OZqYFTe/h9SsCH/vp601k5hmYNZwDmkCaEF17f5zJvz7xmkOm0lRcSVOVi19tys7/pcm5mZldBMz3SuJ03uvBmIXFlgKB0vc9B2CYM38u/VNNe1m5l1CfX8i3cqcIWk7+d+HEmakPmSpP0jYgrwaWASQEQ8LWk18C3eGsEsJC9zEBEP5tttu0bEvEp10inTZmaVU7egExHTJN0OPAY8R3p+swz4LHC5pM2AP5KWnC64HrgQKDzbOYV0i/BWSc+RCn++KOks0q23HYH28p03lXR2RFxQ2SszM7P21HWejqQ+EbEiB5jJwMkRMXMdjl+7pIGkfYHzI+LgSvaxGZc2cMq0mdVTR/N06l0G58qcADATuKmjgCPpDElz88+X2yxp8DXgWmAvSbMk7ZxTpFvzsYdJmilpdq42jaSxkn5a/Us0M7OCuj5Mj4jjy2knaTjpNts+gICHgU8BhwEHRMQLkh4GzoyII/MxhWO3BX4GjIqIZyRtVfELMTOzsjRLBtd+wC0R8SpAzmArd3LnvsDkiHgGICJe7OwAL21gZlYd9b691pA8T8fMrDqaJehMAT4uaTNJmwNH533leAgYVahm4NtrZmb107C31ySdDnwemBkRYySNBwr1134eEY8WrQLakS+Slqa+WdIuwDzSs6GvkJ4NdcjzdMzMKqdhlzYoToeu4DnvJyUblL1WgVOmzczWTSOnTJfUNh1a0oOSHpX0B0kfzG3GSrpV0j2SFkk6LadVP5qrVG+V242XdGyJz1gkaZvaXpmZWffWkEEnIk4B/gIcAFwG7B8RewD/DnyvqOkQ4BPAXqTq0q/ldg8C/ue+mVmDadhnOkW2AK7Oz2OCtNR0wcRcoXq5pGWkStWQSuoMW98PdMq0mVl1NORIp43/IAWXIcBHgd5F771RtL2m6PUaNiCgOmXazKw6mmWk8+e8PbaO/TAzq6o333yTxYsXs3Llynp3pSy9e/emf//+9OrVq/PGWTMEnf8k3V47B7iz1h/ulGkzq5XFixfTt29fBgwYQJlTQuomIli6dCmLFy9mxx137PyArGFTphuFU6bNrFbmz5/PwIEDGz7gFEQECxYsYNCgQW/bX5eUaUkDJC3IKctPSJog6WBJUyU9KWlvSedKOrPomLn5uM0l3ZmrQs+VNDq/P1zSJEkzJN0lafu8v7ii9DaSFuXtstKqzcwaRbMEHFi/vlY7keADwA+BgfnneFLxzjOBb3Rw3GHAXyJi95xA8Lu8KuhPgGMjYjgwjpQm3RmnVZuZNYhqB51nImJORKwhlZ+5N9L9vDnAgA6OmwMcIukHeenqZaSVQIcA9+Q1eM4B+pfRh4kRsTwinietTFqcVl2yD5JOljRd0vRVry0v4yPMzBrLqlWr6t2FkqoddDpLaV7Vpg+9ASLiCWBPUmA4X9K/k9bRmRcRLflnaEQcmo8rPk9xSnU5fXgHp0ybWSNYtGgRgwYN4qSTTmLw4MEceuihvP7660ybNo1hw4bR0tLCWWedxZAhQwAYP348Rx11FAceeCAHHXQQK1as4KqPy2UAAA3uSURBVKCDDmLPPfdk6NCh3HbbbWvPO3DgQMaOHcuuu+7KmDFj+P3vf8/IkSPZZZddeOSRVOZy0qRJtLS00NLSwh577MHy5Rv+j/B6z9NZRAouSNoTKFSC3oF0G+xa4MLcZiGwraQRuU0vSYOLzjM8b7+j5I2ZWbN68sknOfXUU5k3bx79+vXjpptu4oQTTuCKK65g1qxZ9OjR423tZ86cyY033sikSZPo3bs3t9xyCzNnzmTixIl89atfpZA89tRTT/HVr36VBQsWsGDBAn71q1/xwAMPcNFFF/G976XCLxdddBGXXHIJs2bNYsqUKWy66aYbfD31Tpm+CfiMpHmkis9P5P1DgQslrQHeBD4fEX/PNdR+LGkLUt9/RLptdxHwP7mSQEXTqp0ybWb1tOOOO9LS0gLA8OHDWbRoEcuXL2fEiBEAHH/88dxxxx1r2x9yyCFstVXKkYoIvvGNbzB58mQ22mgj/vznP/Pcc8+tPe/QoUMBGDx4MAcddBCSGDp0KIsWLQJg5MiRnHHGGYwZM4ZPfOIT9O9fzhONjlUt6ETEItIzmMLrse28dyjvtAi4q8Q5ZwGjSuxfAAyTdC6wIiIG5P3jgfFF7QYUbb/tPTOzRrTJJpus3e7RowdLlizpsP3mm2++dnvChAk8//zzzJgxg169ejFgwIC1E0+Lz7vRRhutfb3RRhutfR509tln85GPfITf/OY3jBw5krvuuouBAwdu0PXUe6TT8OYvXsrws66pdzc65bk5Zt1Dv3796Nu3Lw8//DD77LMPv/71r9ttu2zZMrbbbjt69erFxIkTefbZZ9fps55++mmGDh3K0KFDmTZtGgsWLNjgoFPvZzobTNI38zygB0gZbkg6SdK0PM/nprziaF9Jz+TUayS9q/i1mVmzuOqqqzjppJNoaWnh1VdfZYsttijZbsyYMUyfPp2hQ4dyzTXXrHPA+NGPfsSQIUMYNmwYvXr14vDDD9/gvjd1RQJJw0m3yPYhjdpmApcDv4iIpbnN+cBzEfETSb8AbouIW/Pznw9GxFdLnLe4yvTwIf/6XzW5ng3hkY5Z85s/f/47ZveXsmLFCvr06QPABRdcwJIlS7j44our3b2SSvW56RZxWwf7A7dExGsR8Qpwe94/RNIUSXOAMUAhy+3nwAl5+wTgF6VO6pRpM2tkd955Jy0tLQwZMoQpU6Zwzjnn1LtLZeuqz3TGAx+PiNmSxgIfBoiIqbnMzoeBHhExt249NDNbT6NHj2b06NH17sZ6afagMxkYL+n7pGv5KHAF0BdYkp/XjOGtpREArgF+RVqnp1NOmTYzq5ymvr0WETOB64HZwG+Bafmtb5Hm/UwlBaOdiw6bAGwJTJXkkY6ZWQ013UhHUo+IWF14HRHfpXThz8vaOcV+wI3AK+V8nlOmzcwqp6FGOkXLIUyQNF/SjTndeVEu/jkTOE7SoZIelDRT0g2S+uTjL5D0uKTHJF2U961dPkHSr0kjnVbg1Hpdp5lZd9VQQSf7IHBpRAwijUa+kPcvjYg9gd+TKkwfnF9PB86QtDVwNDA4IoYB55c4927AIfncZmZWwoknnsh22223tpBoJTXi7bU/RcTUvH0tcHrevj7/3pcUPKbmBYQ2Jq2NswxYCVwl6Q7grWJEgKR+QL+ImJx3/RIoOdOpzTydClySmdn6qfTt/XJuxY8dO5bTTjuNz3ym8rftG3Gk03a2auH1q/m3gHuKljjYLSI+FxGrgL1Jz2uOBH633h3wPB0z68ZGjRq1tmhopTVi0HlfYfkC0kqjD7R5/yFgpKQPAOSlrXfNz3W2iIjfAF8Bdi8+KCJeBl6WtF/eNaZqV2BmZiU14u21hcCpksYBj5Oy0L5YeDMins8TPn+blz54g/SM5xTgCEl/J42Gzihx7hOAcZICuLuczniejplZ5TRi0FkVEZ9qs29A8YuIuE/SVOCOiLgx776dEoEmIs4t2p7B20dA/9ZZZ5ohZdrp0mbWLBrm9pqkAaTMtB0kzZN0t6RN26kY/SHgKNJCb7Mk7SxpfF7kDUkHSXpU0hxJ4yRtkvcvknReTrWeI2nDanSbmdk6aZigkw0ADoyIwcDLwDHAzRGxV0TsDswHPhcRfyCNbM7KyQRPF04gqTep9troiBhKGs19vugzXsip1pcBZ9bgmszMmsonP/lJRowYwcKFC+nfvz9XXXVVxc7daLfXnsmrgwLMIAWhIXl5gn5AH0qsKNrGB/N5CktfX02aCPqj/PrmovN/otQJnDJtZo2iHrfPr7vuuqqdu9FGOm8Uba8mBcXxwGl51HIe0LtCn1E4/zs4ZdrMrDoaLeiU0rZidMHy/F5bC4EBhZRq4NPApOp20czMytFot9dKKVSMfj7/LgSaXwM/k3Q6cGyhcUSslHQCcIOkHYBHSauJtvVtYNvOPtwp02ZmldMwQSciFgFDil5fVPT2OypG51I5uxXtGlv03r3AHiWOGQCpUjWwlPS8p0NOmTazWooIcomvhhfRtoBM5xom6GwoSd8CPkUaEf2JlCgwhDyXR9IiUv22Q4D/rFc/zcza07t3b5YuXcrWW2/d8IEnIli6dCm9e6/bY/YuEXQk7UVKr94d6AXMJAWdtgqVqpF0WO16aGbWuf79+7N48WKef/75enelLL1796Z///7rdEyXCDrASOC2iFgJrJT0v+20u76d/W/jlGkzq4devXqx44471rsbVdUM2WuV9GrnTZwybWZWLV0l6EwFPiqpd642fWS9O2RmZu/UJW6vRcQ0SbcDjwHPAXNIi7ptMKdMm5lVjtYn5a0RSeoTESskbQZMBk6OiJkVOO9y0oTTrmAb4IV6d6JCfC2Nqytdj69l/bw/IkrOg+wSI53sSkm7kcrkXF2JgJMtjIjWCp2rriRN97U0nq50LdC1rsfXUnldJuhExPH17oOZmXWsqyQSmJlZE3DQ6dyV9e5ABflaGlNXuhboWtfja6mwLpNIYGZmjc8jHTMzqxkHnXZIOkzSQklPSTq73v1ZV5IWSZojaZak6XnfVpLukfRk/r1lvfvZHknjJP1N0tyifSX7r+TH+bt6TNKe9ev5O7VzLedK+nP+fmZJOqLova/na1ko6f/Vp9elSXqvpImSHpc0T9KX8v6m+246uJZm/W56S3pE0ux8Pefl/TtKejj3+3pJG+f9m+TXT+X3B9SkoxHhnzY/QA/gaWAnYGNgNrBbvfu1jtewCNimzb7/BM7O22cDP6h3Pzvo/yhgT2BuZ/0HjgB+CwjYF3i43v0v41rOBc4s0Xa3/OdtE2DH/OewR72voah/2wN75u2+wBO5z0333XRwLc363Qjok7d7kdYf2xf4H+Cf8/7Lgc/n7S8Al+ftfwaur0U/PdIpbW/gqYj4Y0T8nbRg3Mfq3KdK+BhvrSF0NfDxOvalQxExGXixze72+v8x4JpIHgL6Sdq+Nj3tXDvX0p6PAb+OiDci4hngKdKfx4YQEUsiz4GLiOXAfOA9NOF308G1tKfRv5uIiBX5Za/8E8CBwI15f9vvpvCd3QgcpBqsp+CgU9p7SGvyFCym4z+MjSiAuyXNyFWzAd4dEUvy9l+Bd9ena+utvf436/d1Wr7lNK7oVmfTXEu+HbMH6V/UTf3dtLkWaNLvRlIPSbOAvwH3kEZjL0fEqtykuM9rrye/vwyoell9B52ua79IawcdDpwqaVTxm5HG1E2butjs/Sethrsz0AIsAX5Y3+6sm1xY9ybgyxHxSvF7zfbdlLiWpv1uImJ1RLQA/UmjsIF17tI7OOiU9mfgvUWv++d9TSMi/px//w24hfQH8LnCrY38+2/16+F6aa//Tfd9RcRz+S+INcDPeOs2TcNfi6RepL+kJ0TEzXl3U343pa6lmb+bgoh4GZgIjCDd0ixUnynu89rrye9vASytdt8cdEqbBuySsz42Jj1ku73OfSqbpM0l9S1sA4cCc0nX8Nnc7LPAbfXp4Xprr/+3A5/JmVL7AsuKbvU0pDbPNY4mfT+QruWfc2bRjsAuwCO17l978j3/q4D5EfFfRW813XfT3rU08XezraR+eXtT4BDSc6qJwLG5WdvvpvCdHQvcl0ep1VXvjItG/SFl3TxBuif6zXr3Zx37vhMpy2Y2MK/Qf9L92nuBJ4HfA1vVu68dXMN1pFsbb5LuQ3+uvf6TsnYuyd/VHKC13v0v41p+mfv6GOl//u2L2n8zX8tC4PB697/NtexHunX2GDAr/xzRjN9NB9fSrN/NMODR3O+5wL/n/TuRguNTwA3AJnl/7/z6qfz+TrXopysSmJlZzfj2mpmZ1YyDjpmZ1YyDjpmZ1YyDjpmZ1YyDjpmZ1YyDjlkDknS6pPmSJtS7L2aV5JRpswYkaQFwcEQsLtrXM96qoWXWlDzSMWswki4nTej7raRlkn4paSrwyzzr/CZJ0/LPyHzM1pLuzuuo/FzSs5K2qeuFmJXgkY5ZA5K0CGgFTgM+Sirg+rqkXwGXRsQDkt4H3BURgyT9GHghIr4j6SPAHcC2EfFCva7BrJSenTcxszq7PSJez9sHA7sVLXvyrlwleRTwCYCIuFPSS7XvplnnHHTMGt+rRdsbAftGxMriBjVYe8usIvxMx6y53A18sfBCUkvenAwcn/cdDmz5zkPN6s9Bx6y5nA605lUtHwdOyfvPA0ZJmke6zfZ/9eqgWUecSGDWBRUSEZxIYI3GIx0zM6sZj3TMzKxmPNIxM7OacdAxM7OacdAxM7OacdAxM7OacdAxM7OacdAxM7Oa+f9XEmiz3A3toAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thres = 5 #<-- min frequency\n",
        "X_top_words = len(df_freq_x[df_freq_x[\"freq\"] > thres])\n",
        "y_top_words = len(df_freq_y[df_freq_y[\"freq\"] > thres])\n",
        "\n",
        "X_top_words, y_top_words"
      ],
      "metadata": {
        "id": "2YlzY5rG8boo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffaf56b-2487-476f-8e9f-c79f1e7b4d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(878, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_corpus = df_train[\"text_clean\"]\n",
        "tokenizer = kprocessing.text.Tokenizer(num_words=X_top_words, lower=False, split=' ', oov_token=None, \n",
        "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(lst_corpus)\n",
        "X_dic_vocabulary = {\"<PAD>\":0}\n",
        "X_dic_vocabulary.update(tokenizer.word_index)\n",
        "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
        "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                    maxlen=15, padding=\"post\", truncating=\"post\")\n",
        "fitted_tokenizer = tokenizer"
      ],
      "metadata": {
        "id": "kEU4tnIb9wql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_corpus = df_train[\"y_clean\"]\n",
        "tokenizer = kprocessing.text.Tokenizer(num_words=y_top_words, lower=False, split=' ', oov_token=None, \n",
        "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(lst_corpus)\n",
        "y_dic_vocabulary = {\"<PAD>\":0}\n",
        "y_dic_vocabulary.update(tokenizer.word_index)\n",
        "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
        "y_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                    maxlen=15, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "8NlFLNDuJaUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## text to sequence with the fitted tokenizer\n",
        "lst_text2seq = tokenizer.texts_to_sequences(df_test[\"text_clean\"])\n",
        "## padding sequence\n",
        "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, maxlen=15,\n",
        "             padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "rtQ0xJrI918y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens = (\"<START>\", \"<END>\")\n",
        "df_train[\"y_clean\"] = df_train['y_clean'].apply(lambda x: \n",
        "                     special_tokens[0]+' '+x+' '+special_tokens[1])\n",
        "df_test[\"y_clean\"] = df_test['y_clean'].apply(lambda x: \n",
        "                     special_tokens[0]+' '+x+' '+special_tokens[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oMKZE3Q97qX",
        "outputId": "12dce49c-5c06-47cf-9e20-4eb8bab9e0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(df_train[\"y_clean\"])\n",
        "fitted_tokenizer = tokenizer"
      ],
      "metadata": {
        "id": "oLcOsjY5MmGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "nlp = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "id": "FGY3w1yNBcG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_units = 250\n",
        "embeddings_size = 300\n",
        "##------------ ENCODER (embedding + lstm) ------------------------##\n",
        "x_in = layers.Input(name=\"x_in\", shape=(X_train.shape[1],))\n",
        "### embedding\n",
        "layer_x_emb = layers.Embedding(name=\"x_emb\", \n",
        "                               input_dim=len(X_dic_vocabulary),\n",
        "                               output_dim=embeddings_size, \n",
        "                               trainable=True)\n",
        "x_emb = layer_x_emb(x_in)\n",
        "### lstm \n",
        "layer_x_lstm = layers.LSTM(name=\"x_lstm\", units=lstm_units, \n",
        "                           dropout=0.4, return_sequences=True, \n",
        "                           return_state=True)\n",
        "x_out, state_h, state_c = layer_x_lstm(x_emb)\n",
        "##------------ DECODER (embedding + lstm + dense) ----------------##\n",
        "y_in = layers.Input(name=\"y_in\", shape=(None,))\n",
        "### embedding\n",
        "layer_y_emb = layers.Embedding(name=\"y_emb\", \n",
        "                               input_dim=len(y_dic_vocabulary), \n",
        "                               output_dim=embeddings_size, \n",
        "                               trainable=True)\n",
        "y_emb = layer_y_emb(y_in)\n",
        "### lstm \n",
        "layer_y_lstm = layers.LSTM(name=\"y_lstm\", units=lstm_units, \n",
        "                           dropout=0.4, return_sequences=True, \n",
        "                           return_state=True)\n",
        "y_out, _, _ = layer_y_lstm(y_emb, initial_state=[state_h, state_c])\n",
        "### final dense layers\n",
        "layer_dense = layers.TimeDistributed(name=\"dense\",          layer=layers.Dense(units=len(y_dic_vocabulary), activation='softmax'))\n",
        "y_out = layer_dense(y_out)\n",
        "##---------------------------- COMPILE ---------------------------##\n",
        "model = models.Model(inputs=[x_in, y_in], outputs=y_out, \n",
        "                     name=\"Seq2Seq\")\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su_Zi4-sDo3n",
        "outputId": "9b91cc81-294d-488a-d77c-a782f29d01e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Seq2Seq\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " x_in (InputLayer)              [(None, 15)]         0           []                               \n",
            "                                                                                                  \n",
            " y_in (InputLayer)              [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " x_emb (Embedding)              (None, 15, 300)      1561200     ['x_in[0][0]']                   \n",
            "                                                                                                  \n",
            " y_emb (Embedding)              (None, None, 300)    288900      ['y_in[0][0]']                   \n",
            "                                                                                                  \n",
            " x_lstm (LSTM)                  [(None, 15, 250),    551000      ['x_emb[0][0]']                  \n",
            "                                 (None, 250),                                                     \n",
            "                                 (None, 250)]                                                     \n",
            "                                                                                                  \n",
            " y_lstm (LSTM)                  [(None, None, 250),  551000      ['y_emb[0][0]',                  \n",
            "                                 (None, 250),                     'x_lstm[0][1]',                 \n",
            "                                 (None, 250)]                     'x_lstm[0][2]']                 \n",
            "                                                                                                  \n",
            " dense (TimeDistributed)        (None, None, 963)    241713      ['y_lstm[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,193,813\n",
            "Trainable params: 3,193,813\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Encoder\n",
        "encoder_model = models.Model(inputs=x_in, outputs=[x_out, state_h, state_c], name=\"Prediction_Encoder\")\n",
        "encoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1QJXh_wKNuo",
        "outputId": "765ba94f-ed9d-4bba-e00e-7793f234af14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Prediction_Encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " x_in (InputLayer)           [(None, 15)]              0         \n",
            "                                                                 \n",
            " x_emb (Embedding)           (None, 15, 300)           1561200   \n",
            "                                                                 \n",
            " x_lstm (LSTM)               [(None, 15, 250),         551000    \n",
            "                              (None, 250),                       \n",
            "                              (None, 250)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,112,200\n",
            "Trainable params: 2,112,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Decoder\n",
        "## double the lstm units if you used bidirectional lstm\n",
        "lstm_units = lstm_units*2 if any(\"Bidirectional\" in str(layer) for layer in model.layers) else lstm_units\n",
        "## states of the previous time step\n",
        "encoder_out = layers.Input(shape=(X_train.shape[1], lstm_units))\n",
        "state_h, state_c = layers.Input(shape=(lstm_units,)), layers.Input(shape=(lstm_units,))\n",
        "## decoder embeddings\n",
        "y_emb2 = layer_y_emb(y_in)\n",
        "## lstm to predict the next word\n",
        "y_out2, state_h2, state_c2 = layer_y_lstm(y_emb2, initial_state=[state_h, state_c])\n",
        "## softmax to generate probability distribution over the vocabulary\n",
        "probs = layer_dense(y_out2)\n",
        "## compile\n",
        "decoder_model = models.Model(inputs=[y_in, encoder_out, state_h, state_c], outputs=[probs, state_h2, state_c2], name=\"Prediction_Decoder\")\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTyyvYbUKjjF",
        "outputId": "2d6df44d-9cb9-43a6-c1b8-a0850509b480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Prediction_Decoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " y_in (InputLayer)              [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " y_emb (Embedding)              (None, None, 300)    288900      ['y_in[0][0]']                   \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " y_lstm (LSTM)                  [(None, None, 250),  551000      ['y_emb[1][0]',                  \n",
            "                                 (None, 250),                     'input_2[0][0]',                \n",
            "                                 (None, 250)]                     'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 15, 250)]    0           []                               \n",
            "                                                                                                  \n",
            " dense (TimeDistributed)        (None, None, 963)    241713      ['y_lstm[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,081,613\n",
            "Trainable params: 1,081,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeJzq_ztLzfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "max_seq_lenght = X_test.shape[1]\n",
        "predicted = []\n",
        "for x in X_test:\n",
        "   x = x.reshape(1,-1)\n",
        "   ## encode X\n",
        "   encoder_out, state_h, state_c = encoder_model.predict(x)\n",
        "   ## prepare loop\n",
        "   y_in = np.array([fitted_tokenizer.word_index[special_tokens[0]]])\n",
        "   predicted_text = \"\"\n",
        "   stop = False\n",
        "   while not stop:\n",
        "        ## predict dictionary probability distribution\n",
        "        probs, new_state_h, new_state_c = decoder_model.predict(\n",
        "                          [y_in, encoder_out, state_h, state_c])\n",
        "        \n",
        "        ## get predicted word\n",
        "        voc_idx = np.argmax(probs[0,-1,:])\n",
        "        pred_word = fitted_tokenizer.index_word[voc_idx]\n",
        "        \n",
        "        ## check stop\n",
        "        if (pred_word != special_tokens[1]) and (len(predicted_text.split()) < max_seq_lenght):\n",
        "            predicted_text = predicted_text +\" \"+ pred_word\n",
        "        else:\n",
        "            stop = True\n",
        "        \n",
        "        ## next\n",
        "        y_in = np.array([voc_idx])\n",
        "        state_h, state_c = new_state_h, new_state_c\n",
        "   predicted_text = predicted_text.replace(\n",
        "                    special_tokens[0],\"\").strip()\n",
        "   predicted.append(predicted_text)\n"
      ],
      "metadata": {
        "id": "yhfsTf88Kule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Best Known Abstractive Approach: Using BART \n",
        "\n",
        "BART is an algot"
      ],
      "metadata": {
        "id": "ano6RPdDNBl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bart(corpus):    \n",
        "    summarizer = transformers.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") \n",
        "    summaries = []\n",
        "    for text in corpus:\n",
        "      try:\n",
        "        summaries.append(summarizer(text, max_length=500, min_length=30, do_sample=False))\n",
        "      except:\n",
        "        summaries.append(\" \")\n",
        "    return [s[0][\"summary_text\"].replace(\" .\", \".\") for s in summaries]    "
      ],
      "metadata": {
        "id": "9Tcl9D0qKy-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_summaries = bart(df_test[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "uxuc_8VkVE-B",
        "outputId": "7181eeea-f7cf-4430-ba26-afacf11fe3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Your max_length is set to 500, but you input_length is only 454. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=227)\n",
            "Your max_length is set to 500, but you input_length is only 466. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=233)\n",
            "Your max_length is set to 500, but you input_length is only 402. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=201)\n",
            "Your max_length is set to 500, but you input_length is only 301. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=150)\n",
            "Your max_length is set to 500, but you input_length is only 271. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=135)\n",
            "Your max_length is set to 500, but you input_length is only 336. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=168)\n",
            "Your max_length is set to 500, but you input_length is only 319. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=159)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-aabf38d5ec49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-2b79711fc061>\u001b[0m in \u001b[0;36mbart\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" .\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-2b79711fc061>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" .\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_predicted_summary, sample_expected_summary = predicted_summaries[0], df_test[\"y\"][0]\n",
        "evaluate_summary(sample_predicted_summary, sample_expected_summary)\n",
        "print(f\"For {SAMPLES} summaaries:\")\n",
        "evaluate_summary(predicted_summaries, list(df_test[\"y\"]))"
      ],
      "metadata": {
        "id": "f3JKkAuhNU3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_differance(sample_predicted_summary, df_test[\"text\"][0])"
      ],
      "metadata": {
        "id": "gH0QnJWVN0oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis of Text\n",
        "\n",
        "Similar to the construction of any NLP model, this process would involve processing the data, tokenizing it and using the fitted tokenizer to transform it. \n",
        "\n",
        "For this part of the project we will heavily utilise the tensorflow library"
      ],
      "metadata": {
        "id": "OJw-H54JVo9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "metadata": {
        "id": "V9nlfb_DN6yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = [\"positive\", \"negative\", \"nuetral\"]"
      ],
      "metadata": {
        "id": "HghDtn4BYiar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df_train[\"y\"]\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "encoded_docs = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
      ],
      "metadata": {
        "id": "lUMYg6v5WGug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential() \n",
        "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200) )\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid')) \n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])  \n",
        "print(model.summary()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOypjWAtWSmx",
        "outputId": "488f62a3-4b59-4b8d-a15e-8289a4738c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 32)           38848     \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 200, 32)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                16600     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,499\n",
            "Trainable params: 55,499\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    tw = tokenizer.texts_to_sequences([text])\n",
        "    tw = pad_sequences(tw,maxlen=200)\n",
        "    prediction = int(model.predict(tw).round().item())\n",
        "    return sentiments[prediction]"
      ],
      "metadata": {
        "id": "Ctkr_A4kXBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[\"sentiment\"] = [predict_sentiment(s) for s in df_test[\"y\"]]"
      ],
      "metadata": {
        "id": "MalMGArdXTk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "3q-gQl_nX4lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"Kalawati, the widow of a farmer who had committed suicide in Yavatmal managed to meet Rahul Gandhi, who had spoken of her in parliament in 2008, to thank him.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "yjOruShZYf-8",
        "outputId": "d7e26be5-4287-416e-d9f6-9912bc9da529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xe0XScTigZqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}